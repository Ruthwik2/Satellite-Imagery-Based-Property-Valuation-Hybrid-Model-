{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install openpyxl xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths - UPDATE THESE to your Google Drive folder\n",
    "DRIVE_FOLDER = '/content/drive/MyDrive/satellite_project'  # <-- UPDATE THIS\n",
    "\n",
    "TRAIN_PATH = f'{DRIVE_FOLDER}/train.xlsx'\n",
    "TEST_PATH = f'{DRIVE_FOLDER}/test.xlsx'\n",
    "IMAGE_DIR = f'{DRIVE_FOLDER}/mapbox_images'\n",
    "OUTPUT_DIR = '/content/outputs'\n",
    "\n",
    "!mkdir -p {OUTPUT_DIR}\n",
    "\n",
    "import os\n",
    "print(f\"Train: {TRAIN_PATH} - exists: {os.path.exists(TRAIN_PATH)}\")\n",
    "print(f\"Test: {TEST_PATH} - exists: {os.path.exists(TEST_PATH)}\")\n",
    "print(f\"Images: {IMAGE_DIR} - exists: {os.path.exists(IMAGE_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'target_col': 'price',\n",
    "    'lat_col': 'lat',\n",
    "    'lon_col': 'long',\n",
    "    'image_size': 224,\n",
    "    'seed': 42,\n",
    "    'test_size': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 15,\n",
    "    'lr': 5e-4,\n",
    "    'use_log_target': True,\n",
    "}\n",
    "\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b180c7",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(TRAIN_PATH, engine='openpyxl')\n",
    "test_df = pd.read_excel(TEST_PATH, engine='openpyxl')\n",
    "\n",
    "train_df.columns = [c.strip() for c in train_df.columns]\n",
    "test_df.columns = [c.strip() for c in test_df.columns]\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fdade",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = {CONFIG['target_col'], 'date', 'id', CONFIG['lat_col'], CONFIG['lon_col']}\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols and train_df[c].dtype in ['int64', 'float64']]\n",
    "print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec066275",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_df, test_size=CONFIG['test_size'], random_state=CONFIG['seed'])\n",
    "train_image_ids = train_data.index.tolist()\n",
    "val_image_ids = val_data.index.tolist()\n",
    "\n",
    "print(f\"Training: {len(train_data)}, Validation: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a977230",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = preprocessor.fit_transform(train_data[feature_cols])\n",
    "X_val = preprocessor.transform(val_data[feature_cols])\n",
    "X_test = preprocessor.transform(test_df[feature_cols])\n",
    "\n",
    "if CONFIG['use_log_target']:\n",
    "    y_train = np.log1p(train_data[CONFIG['target_col']].values)\n",
    "    y_val = np.log1p(val_data[CONFIG['target_col']].values)\n",
    "    y_train_original = train_data[CONFIG['target_col']].values\n",
    "    y_val_original = val_data[CONFIG['target_col']].values\n",
    "else:\n",
    "    y_train = train_data[CONFIG['target_col']].values\n",
    "    y_val = val_data[CONFIG['target_col']].values\n",
    "    y_train_original = y_train\n",
    "    y_val_original = y_val\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d1a20",
   "metadata": {},
   "source": [
    "## 3. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25aef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=CONFIG['seed'],\n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='rmse',\n",
    "    tree_method='hist',\n",
    "    device='cuda' if DEVICE == 'cuda' else 'cpu'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name}: RMSE=${rmse:,.2f}, RÂ²={r2:.4f}\")\n",
    "    return {'model': model_name, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "xgb_pred_raw = xgb_model.predict(X_val)\n",
    "if CONFIG['use_log_target']:\n",
    "    xgb_pred = np.expm1(xgb_pred_raw)\n",
    "    xgb_results = evaluate_model(y_val_original, xgb_pred, 'XGBoost')\n",
    "else:\n",
    "    xgb_results = evaluate_model(y_val, xgb_pred_raw, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f51a9",
   "metadata": {},
   "source": [
    "## 4. Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2092ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyDataset(Dataset):\n",
    "    def __init__(self, X_tabular, y=None, image_ids=None, train_mode=True):\n",
    "        self.X_tab = X_tabular.astype(np.float32)\n",
    "        self.y = y.astype(np.float32) if y is not None else None\n",
    "        self.image_ids = image_ids\n",
    "        \n",
    "        if train_mode:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                T.RandomVerticalFlip(0.5),\n",
    "                T.RandomRotation(15),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        \n",
    "        self.blank = Image.new('RGB', (CONFIG['image_size'], CONFIG['image_size']), (128, 128, 128))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_tab)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx] if self.image_ids is not None else idx\n",
    "        img_path = os.path.join(IMAGE_DIR, f'img_{int(img_id)}.png')\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB') if os.path.exists(img_path) else self.blank\n",
    "        except:\n",
    "            img = self.blank\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "        tab_tensor = torch.from_numpy(self.X_tab[idx])\n",
    "        \n",
    "        if self.y is None:\n",
    "            return img_tensor, tab_tensor\n",
    "        return img_tensor, tab_tensor, torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.cnn = backbone\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.cnn_processor = nn.Sequential(\n",
    "            nn.Linear(512, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tabular = nn.Sequential(\n",
    "            nn.Linear(tabular_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, tab):\n",
    "        with torch.no_grad():\n",
    "            img_feat = self.cnn(img)\n",
    "        img_feat = self.cnn_processor(img_feat)\n",
    "        tab_feat = self.tabular(tab)\n",
    "        return self.head(torch.cat([img_feat, tab_feat], dim=1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hybrid = y_train_original.astype(np.float32)\n",
    "y_val_hybrid = y_val_original.astype(np.float32)\n",
    "\n",
    "train_dataset = PropertyDataset(X_train, y_train_hybrid, train_image_ids, True)\n",
    "val_dataset = PropertyDataset(X_val, y_val_hybrid, val_image_ids, False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a452cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridModel(X_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    model.train()\n",
    "    for img, tab, y in tqdm(train_loader, desc=f'Epoch {epoch}', leave=False):\n",
    "        img, tab, y = img.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(img, tab), y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for img, tab, y in val_loader:\n",
    "            preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "    \n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val_hybrid, preds))\n",
    "    scheduler.step(val_rmse)\n",
    "    \n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        print(f\"Epoch {epoch}: Val RMSE=${val_rmse:,.0f} âœ“\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}: Val RMSE=${val_rmse:,.0f}\")\n",
    "\n",
    "print(f\"\\nBest Val RMSE: ${best_rmse:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10830f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for img, tab, _ in val_loader:\n",
    "        preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "\n",
    "hybrid_results = evaluate_model(y_val_original, np.array(preds), 'Hybrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ff3b0",
   "metadata": {},
   "source": [
    "## 5. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_preds_raw = xgb_model.predict(X_test)\n",
    "test_preds = np.expm1(xgb_test_preds_raw) if CONFIG['use_log_target'] else xgb_test_preds_raw\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'] if 'id' in test_df.columns else range(len(test_preds)),\n",
    "    'predicted_price': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f'{OUTPUT_DIR}/predictions.csv', index=False)\n",
    "print(f\"Saved {len(test_preds)} predictions to {OUTPUT_DIR}/predictions.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879186b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(f'{OUTPUT_DIR}/predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9099b1",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b837eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([xgb_results, hybrid_results])\n",
    "print(\"\\nMODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "display(results_df.round(2))\n",
    "\n",
    "print(f\"\\nXGBoost RMSE: ${xgb_results['RMSE']:,.0f}\")\n",
    "print(f\"Hybrid RMSE: ${hybrid_results['RMSE']:,.0f}\")\n",
    "print(\"\\nâœ… Notebook completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0991d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install openpyxl xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Option 1 - Recommended for large files)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths - UPDATE THESE to your Google Drive folder\n",
    "# Example: If your files are in 'My Drive/satellite_project/'\n",
    "DRIVE_FOLDER = '/content/drive/MyDrive/satellite_project'  # <-- UPDATE THIS\n",
    "\n",
    "TRAIN_PATH = f'{DRIVE_FOLDER}/train.xlsx'\n",
    "TEST_PATH = f'{DRIVE_FOLDER}/test.xlsx'\n",
    "IMAGE_DIR = f'{DRIVE_FOLDER}/mapbox_images'\n",
    "OUTPUT_DIR = '/content/outputs'\n",
    "\n",
    "!mkdir -p {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89250ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR Upload files directly (Option 2 - For smaller files)\n",
    "# Uncomment below if not using Google Drive\n",
    "\n",
    "# from google.colab import files\n",
    "# print(\"Upload train.xlsx:\")\n",
    "# uploaded = files.upload()\n",
    "# print(\"Upload test.xlsx:\")\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# TRAIN_PATH = 'train.xlsx'\n",
    "# TEST_PATH = 'test.xlsx'\n",
    "# IMAGE_DIR = '/content/mapbox_images'  # Upload images separately\n",
    "# OUTPUT_DIR = '/content/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For images: Upload a zip file and extract\n",
    "# Uncomment if uploading images as zip\n",
    "\n",
    "# from google.colab import files\n",
    "# print(\"Upload mapbox_images.zip:\")\n",
    "# uploaded = files.upload()\n",
    "# !unzip -q mapbox_images.zip -d /content/\n",
    "# IMAGE_DIR = '/content/mapbox_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"âœ… Device: {DEVICE}\")\n",
    "print(f\"âœ… PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85152c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "CONFIG = {\n",
    "    'target_col': 'price',\n",
    "    'lat_col': 'lat',\n",
    "    'lon_col': 'long',\n",
    "    'image_size': 224,\n",
    "    'seed': 42,\n",
    "    'test_size': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'lr': 1e-4,\n",
    "}\n",
    "\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e68a5a",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34572df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify paths exist\n",
    "print(f\"Train file exists: {os.path.exists(TRAIN_PATH)}\")\n",
    "print(f\"Test file exists: {os.path.exists(TEST_PATH)}\")\n",
    "print(f\"Image dir exists: {os.path.exists(IMAGE_DIR)}\")\n",
    "\n",
    "if os.path.exists(IMAGE_DIR):\n",
    "    n_images = len([f for f in os.listdir(IMAGE_DIR) if f.endswith('.png')])\n",
    "    print(f\"Number of images: {n_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_excel(TRAIN_PATH, engine='openpyxl')\n",
    "test_df = pd.read_excel(TEST_PATH, engine='openpyxl')\n",
    "\n",
    "train_df.columns = [c.strip() for c in train_df.columns]\n",
    "test_df.columns = [c.strip() for c in test_df.columns]\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect correct image naming (by ID or by index)\n",
    "print(\"\\nðŸ” Detecting image naming convention...\")\n",
    "sample_images = sorted(os.listdir(IMAGE_DIR))[:5] if os.path.exists(IMAGE_DIR) else []\n",
    "print(f\"Sample images: {sample_images}\")\n",
    "\n",
    "# Check if images match ID column or row index\n",
    "if 'id' in train_df.columns:\n",
    "    test_id = train_df.iloc[0]['id']\n",
    "    test_by_id = os.path.exists(os.path.join(IMAGE_DIR, f'img_{int(test_id)}.png'))\n",
    "else:\n",
    "    test_by_id = False\n",
    "test_by_idx = os.path.exists(os.path.join(IMAGE_DIR, 'img_0.png'))\n",
    "\n",
    "USE_ID_FOR_IMAGES = test_by_id\n",
    "\n",
    "print(f\"âœ… Images by ID: {test_by_id}, by index: {test_by_idx}\")plt.show()\n",
    "\n",
    "print(f\"âž¡ï¸ Using {'ID column' if USE_ID_FOR_IMAGES else 'row index'} for image lookup\")plt.tight_layout()\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "def get_image_path_by_id(row):        ax.text(0.5, 0.5, 'No Image', ha='center', va='center')\n",
    "\n",
    "    \"\"\"Get image path using ID column.\"\"\"    else:\n",
    "\n",
    "    if USE_ID_FOR_IMAGES and 'id' in row.index:        ax.set_title(f'Price: ${row[\"price\"]:,.0f}')\n",
    "\n",
    "        return os.path.join(IMAGE_DIR, f'img_{int(row[\"id\"])}.png')        ax.imshow(Image.open(img_path))\n",
    "\n",
    "    return None    if os.path.exists(img_path):\n",
    "\n",
    "        img_path = os.path.join(IMAGE_DIR, f'img_{i}.png')\n",
    "\n",
    "# Show sample images    else:\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))        img_path = os.path.join(IMAGE_DIR, f'img_{int(row[\"id\"])}.png')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):    if USE_ID_FOR_IMAGES and 'id' in train_df.columns:\n",
    "    row = train_df.iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadd1db",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns\n",
    "exclude = {CONFIG['target_col'], 'date', 'id', CONFIG['lat_col'], CONFIG['lon_col']}\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude and train_df[c].dtype in ['int64', 'float64']]\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_data, val_data = train_test_split(train_df, test_size=CONFIG['test_size'], random_state=CONFIG['seed'])\n",
    "\n",
    "# Store IMAGE IDs (not row indices!) for correct image lookup\n",
    "if USE_ID_FOR_IMAGES and 'id' in train_df.columns:\n",
    "    train_image_ids = train_data['id'].tolist()\n",
    "    val_image_ids = val_data['id'].tolist()\n",
    "    print(\"Using 'id' column for image lookup\")\n",
    "else:\n",
    "    train_image_ids = train_data.index.tolist()\n",
    "    val_image_ids = val_data.index.tolist()\n",
    "    print(\"Using row index for image lookup\")\n",
    "\n",
    "# Preprocess\n",
    "preprocessor = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "X_train = preprocessor.fit_transform(train_data[feature_cols])print(f\"X_train: {X_train.shape}\")\n",
    "\n",
    "X_val = preprocessor.transform(val_data[feature_cols])\n",
    "\n",
    "X_test = preprocessor.transform(test_df[feature_cols])y_val = val_data[CONFIG['target_col']].values\n",
    "\n",
    "y_train = train_data[CONFIG['target_col']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18272c16",
   "metadata": {},
   "source": [
    "## 3. Model 1: XGBoost (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
    "    early_stopping_rounds=50, eval_metric='rmse',\n",
    "    tree_method='hist', device='cuda'\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{name}: RMSE=${rmse:,.0f}, MAE=${mae:,.0f}, RÂ²={r2:.4f}\")\n",
    "    return {'model': name, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "xgb_results = evaluate(y_val, xgb.predict(X_val), 'XGBoost (Tabular)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b3ec6",
   "metadata": {},
   "source": [
    "## 4. Model 2: Hybrid (Tabular + Satellite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b008cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyDataset(Dataset):\n",
    "    def __init__(self, X, y=None, image_ids=None, train_mode=True):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32) if y is not None else None\n",
    "        self.image_ids = image_ids  # IDs for img_{id}.png lookup\n",
    "        \n",
    "        transforms = [T.Resize((224, 224)), T.ToTensor(), T.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])]\n",
    "        if train_mode:\n",
    "            transforms.insert(1, T.RandomHorizontalFlip(0.5))\n",
    "        self.transform = T.Compose(transforms)\n",
    "        self.blank = Image.new('RGB', (224, 224), (128, 128, 128))\n",
    "    \n",
    "    def __len__(self): return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Use image ID (not row index!) for correct image lookup\n",
    "        img_id = self.image_ids[idx] if self.image_ids is not None else idx\n",
    "        img_path = os.path.join(IMAGE_DIR, f'img_{int(img_id)}.png')\n",
    "        img = Image.open(img_path).convert('RGB') if os.path.exists(img_path) else self.blank\n",
    "        img_t = self.transform(img)\n",
    "\n",
    "        tab_t = torch.from_numpy(self.X[idx])        return (img_t, tab_t) if self.y is None else (img_t, tab_t, torch.tensor(self.y[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6000d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, tab_dim):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.cnn = nn.Sequential(*list(backbone.children())[:-1], nn.Flatten())\n",
    "        self.tab = nn.Sequential(nn.Linear(tab_dim, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 64), nn.ReLU())\n",
    "        self.head = nn.Sequential(nn.Linear(512+64, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 1))\n",
    "    \n",
    "    def forward(self, img, tab):\n",
    "        return self.head(torch.cat([self.cnn(img), self.tab(tab)], dim=1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94385d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders with CORRECT image IDs\n",
    "train_loader = DataLoader(PropertyDataset(X_train, y_train, train_image_ids, True), batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(PropertyDataset(X_val, y_val, val_image_ids, False), batch_size=32, num_workers=2)\n",
    "\n",
    "# Model\n",
    "model = HybridModel(X_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3513497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "best_rmse, best_state = float('inf'), None\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    model.train()\n",
    "    for img, tab, y in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "        img, tab, y = img.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(img, tab), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for img, tab, _ in val_loader:\n",
    "            preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        print(f\"Epoch {epoch+1}: RMSE=${rmse:,.0f} âœ“\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}: RMSE=${rmse:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model\n",
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for img, tab, _ in val_loader:\n",
    "        preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "\n",
    "hybrid_results = evaluate(y_val, np.array(preds), 'Hybrid (Tabular + Satellite)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39beb896",
   "metadata": {},
   "source": [
    "## 5. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([xgb_results, hybrid_results])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "display(results)\n",
    "\n",
    "improvement = (xgb_results['RMSE'] - hybrid_results['RMSE']) / xgb_results['RMSE'] * 100\n",
    "print(f\"\\nðŸ“ˆ Improvement from satellite images: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c061f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].bar(results['model'], results['RMSE'], color=['steelblue', 'coral'])\n",
    "ax[0].set_title('RMSE (Lower is Better)')\n",
    "ax[1].bar(results['model'], results['R2'], color=['steelblue', 'coral'])\n",
    "ax[1].set_title('RÂ² (Higher is Better)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77020de8",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions with correct image IDs\n",
    "if USE_ID_FOR_IMAGES and 'id' in test_df.columns:\n",
    "    test_image_ids = test_df['id'].tolist()\n",
    "else:\n",
    "    test_image_ids = list(range(len(test_df)))\n",
    "test_loader = DataLoader(PropertyDataset(X_test, None, test_image_ids, False), batch_size=32, num_workers=2)\n",
    "\n",
    "model.eval()\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for img, tab in tqdm(test_loader):\n",
    "        test_preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "\n",
    "# Save\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'] if 'id' in test_df.columns else range(len(test_preds)),\n",
    "    'predicted_price': test_preds\n",
    "\n",
    "})submission.head()\n",
    "\n",
    "submission.to_csv(f'{OUTPUT_DIR}/predictions.csv', index=False)print(f\"âœ… Saved to {OUTPUT_DIR}/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download predictions\n",
    "from google.colab import files\n",
    "files.download(f'{OUTPUT_DIR}/predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
