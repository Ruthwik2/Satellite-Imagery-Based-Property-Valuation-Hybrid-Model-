{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71554d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# XGBoost for tabular baseline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from data_fetcher import SatelliteImageFetcher\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'target_col': 'price',\n",
    "    'lat_col': 'lat',\n",
    "    'lon_col': 'long',\n",
    "    'image_size': 224,\n",
    "    'seed': 42,\n",
    "    'test_size': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 15,\n",
    "    'lr': 5e-4,\n",
    "    'use_log_target': True,\n",
    "}\n",
    "\n",
    "# Paths - UPDATE THESE\n",
    "DATA_DIR = '../data'\n",
    "IMAGE_DIR = '../data/mapbox_images'\n",
    "OUTPUT_DIR = '../outputs'\n",
    "TRAIN_PATH = f'{DATA_DIR}/train.xlsx'\n",
    "TEST_PATH = f'{DATA_DIR}/test.xlsx'\n",
    "\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6d7c1",
   "metadata": {},
   "source": [
    "## 1. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(TRAIN_PATH, engine='openpyxl')\n",
    "test_df = pd.read_excel(TEST_PATH, engine='openpyxl')\n",
    "\n",
    "train_df.columns = [c.strip() for c in train_df.columns]\n",
    "test_df.columns = [c.strip() for c in test_df.columns]\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10416474",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = {CONFIG['target_col'], 'date', 'id', CONFIG['lat_col'], CONFIG['lon_col']}\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols and train_df[c].dtype in ['int64', 'float64']]\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31895301",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_df, test_size=CONFIG['test_size'], random_state=CONFIG['seed'])\n",
    "train_image_ids = train_data.index.tolist()\n",
    "val_image_ids = val_data.index.tolist()\n",
    "\n",
    "print(f\"Training: {len(train_data)}, Validation: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = preprocessor.fit_transform(train_data[feature_cols])\n",
    "X_val = preprocessor.transform(val_data[feature_cols])\n",
    "X_test = preprocessor.transform(test_df[feature_cols])\n",
    "\n",
    "if CONFIG['use_log_target']:\n",
    "    y_train = np.log1p(train_data[CONFIG['target_col']].values)\n",
    "    y_val = np.log1p(val_data[CONFIG['target_col']].values)\n",
    "    y_train_original = train_data[CONFIG['target_col']].values\n",
    "    y_val_original = val_data[CONFIG['target_col']].values\n",
    "else:\n",
    "    y_train = train_data[CONFIG['target_col']].values\n",
    "    y_val = val_data[CONFIG['target_col']].values\n",
    "    y_train_original = y_train\n",
    "    y_val_original = y_val\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6336c07",
   "metadata": {},
   "source": [
    "## 2. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce88cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{model_name}: RMSE=${rmse:,.2f}, RÂ²={r2:.4f}\")\n",
    "    return {'model': model_name, 'RMSE': rmse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57deca",
   "metadata": {},
   "source": [
    "## 3. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=CONFIG['seed'],\n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='rmse',\n",
    "    tree_method='hist',\n",
    "    device='cuda' if DEVICE == 'cuda' else 'cpu'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_raw = xgb_model.predict(X_val)\n",
    "if CONFIG['use_log_target']:\n",
    "    xgb_pred = np.expm1(xgb_pred_raw)\n",
    "    xgb_results = evaluate_model(y_val_original, xgb_pred, 'XGBoost')\n",
    "else:\n",
    "    xgb_results = evaluate_model(y_val, xgb_pred_raw, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd0823",
   "metadata": {},
   "source": [
    "## 4. Hybrid CNN+Tabular Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropertyDataset(Dataset):\n",
    "    def __init__(self, X_tabular, y=None, image_ids=None, train_mode=True):\n",
    "        self.X_tab = X_tabular.astype(np.float32)\n",
    "        self.y = y.astype(np.float32) if y is not None else None\n",
    "        self.image_ids = image_ids\n",
    "        \n",
    "        if train_mode:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                T.RandomVerticalFlip(0.5),\n",
    "                T.RandomRotation(15),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        \n",
    "        self.blank = Image.new('RGB', (CONFIG['image_size'], CONFIG['image_size']), (128, 128, 128))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_tab)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx] if self.image_ids is not None else idx\n",
    "        img_path = os.path.join(IMAGE_DIR, f'img_{int(img_id)}.png')\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB') if os.path.exists(img_path) else self.blank\n",
    "        except:\n",
    "            img = self.blank\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "        tab_tensor = torch.from_numpy(self.X_tab[idx])\n",
    "        \n",
    "        if self.y is None:\n",
    "            return img_tensor, tab_tensor\n",
    "        return img_tensor, tab_tensor, torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8101d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.cnn = backbone\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.cnn_processor = nn.Sequential(\n",
    "            nn.Linear(512, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tabular = nn.Sequential(\n",
    "            nn.Linear(tabular_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, tab):\n",
    "        with torch.no_grad():\n",
    "            img_feat = self.cnn(img)\n",
    "        img_feat = self.cnn_processor(img_feat)\n",
    "        tab_feat = self.tabular(tab)\n",
    "        return self.head(torch.cat([img_feat, tab_feat], dim=1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders for Hybrid model\n",
    "y_train_hybrid = y_train_original.astype(np.float32)\n",
    "y_val_hybrid = y_val_original.astype(np.float32)\n",
    "\n",
    "train_dataset = PropertyDataset(X_train, y_train_hybrid, train_image_ids, True)\n",
    "val_dataset = PropertyDataset(X_val, y_val_hybrid, val_image_ids, False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid Model\n",
    "model = HybridModel(X_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    model.train()\n",
    "    for img, tab, y in tqdm(train_loader, desc=f'Epoch {epoch}', leave=False):\n",
    "        img, tab, y = img.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(img, tab), y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for img, tab, y in val_loader:\n",
    "            preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "    \n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val_hybrid, preds))\n",
    "    scheduler.step(val_rmse)\n",
    "    \n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        print(f\"Epoch {epoch}: Val RMSE=${val_rmse:,.0f} âœ“\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}: Val RMSE=${val_rmse:,.0f}\")\n",
    "\n",
    "print(f\"\\nBest Val RMSE: ${best_rmse:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Hybrid Model\n",
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for img, tab, _ in val_loader:\n",
    "        preds.extend(model(img.to(DEVICE), tab.to(DEVICE)).cpu().numpy())\n",
    "\n",
    "hybrid_results = evaluate_model(y_val_original, np.array(preds), 'Hybrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffa2cf",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e197167",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([xgb_results, hybrid_results])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "display(results_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42fe35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].bar(results_df['model'], results_df['RMSE'], color=['steelblue', 'coral'])\n",
    "ax[0].set_title('RMSE by Model')\n",
    "ax[0].set_ylabel('RMSE ($)')\n",
    "\n",
    "ax[1].bar(results_df['model'], results_df['R2'], color=['steelblue', 'coral'])\n",
    "ax[1].set_title('RÂ² by Model')\n",
    "ax[1].set_ylabel('RÂ²')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/model_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ab3af",
   "metadata": {},
   "source": [
    "## 6. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save XGBoost model\n",
    "joblib.dump(xgb_model, f'{OUTPUT_DIR}/xgb_model.joblib')\n",
    "print(f\"Saved XGBoost model to {OUTPUT_DIR}/xgb_model.joblib\")\n",
    "\n",
    "# Save Hybrid model\n",
    "torch.save(best_state, f'{OUTPUT_DIR}/hybrid_model.pth')\n",
    "print(f\"Saved Hybrid model to {OUTPUT_DIR}/hybrid_model.pth\")\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, f'{OUTPUT_DIR}/preprocessor.joblib')\n",
    "print(f\"Saved preprocessor to {OUTPUT_DIR}/preprocessor.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654c49b",
   "metadata": {},
   "source": [
    "## 7. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions using XGBoost model\n",
    "xgb_test_preds_raw = xgb_model.predict(X_test)\n",
    "test_preds = np.expm1(xgb_test_preds_raw) if CONFIG['use_log_target'] else xgb_test_preds_raw\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'] if 'id' in test_df.columns else range(len(test_preds)),\n",
    "    'predicted_price': test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f'{OUTPUT_DIR}/predictions.csv', index=False)\n",
    "print(f\"Saved {len(test_preds)} predictions to {OUTPUT_DIR}/predictions.csv\")\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef133f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâœ… Training complete!\")\n",
    "print(f\"XGBoost RMSE: ${xgb_results['RMSE']:,.0f}\")\n",
    "print(f\"Hybrid RMSE: ${hybrid_results['RMSE']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec50f7e",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'train_path': '../data/train.xlsx',\n",
    "    'test_path': '../data/test.xlsx',\n",
    "    'target_col': 'price',\n",
    "    'lat_col': 'lat',\n",
    "    'lon_col': 'long',\n",
    "    'image_cache': '../image_cache',\n",
    "    'image_size': 224,\n",
    "    'seed': 42,\n",
    "    'test_size': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 15,\n",
    "    'lr': 1e-4,\n",
    "}\n",
    "\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_excel(CONFIG['train_path'], engine='openpyxl')\n",
    "test_df = pd.read_excel(CONFIG['test_path'], engine='openpyxl')\n",
    "\n",
    "train_df.columns = [c.strip() for c in train_df.columns]\n",
    "test_df.columns = [c.strip() for c in test_df.columns]\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (exclude id, date, target, coordinates for tabular model)\n",
    "exclude_cols = {CONFIG['target_col'], 'date', 'id', CONFIG['lat_col'], CONFIG['lon_col']}\n",
    "feature_cols = [c for c in train_df.columns if c not in exclude_cols and train_df[c].dtype in ['int64', 'float64']]\n",
    "print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "train_data, val_data = train_test_split(train_df, test_size=CONFIG['test_size'], random_state=CONFIG['seed'])\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = preprocessor.fit_transform(train_data[feature_cols])\n",
    "X_val = preprocessor.transform(val_data[feature_cols])\n",
    "X_test = preprocessor.transform(test_df[feature_cols])\n",
    "\n",
    "y_train = train_data[CONFIG['target_col']].values\n",
    "y_val = val_data[CONFIG['target_col']].values\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603742c",
   "metadata": {},
   "source": [
    "## 2. Baseline Model: Tabular-Only (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost baseline\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=CONFIG['seed'],\n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {model_name} Results:\")\n",
    "    print(f\"   RMSE:  ${rmse:,.2f}\")\n",
    "    print(f\"   MAE:   ${mae:,.2f}\")\n",
    "    print(f\"   RÂ²:    {r2:.4f}\")\n",
    "    print(f\"   MAPE:  {mape:.2f}%\")\n",
    "    \n",
    "    return {'model': model_name, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "xgb_val_pred = xgb_model.predict(X_val)\n",
    "xgb_results = evaluate_model(y_val, xgb_val_pred, 'XGBoost (Tabular Only)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "importance_df.head(15).plot(kind='barh', x='feature', y='importance', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('XGBoost Feature Importance (Top 15)')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/xgb_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d71ae",
   "metadata": {},
   "source": [
    "## 3. Deep Learning Dataset and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image directory with pre-downloaded images\n",
    "IMAGE_DIR = '/Users/ruthwik/Downloads/mapbox_images'\n",
    "\n",
    "# Auto-detect image naming convention\n",
    "print(\"\\n\\ud83d\\udd0d Detecting image naming convention...\")\n",
    "if 'id' in train_df.columns:\n",
    "    test_id = train_df.iloc[0]['id']\n",
    "    test_by_id = os.path.exists(os.path.join(IMAGE_DIR, f'img_{int(test_id)}.png'))\n",
    "else:\n",
    "    test_by_id = False\n",
    "test_by_idx = os.path.exists(os.path.join(IMAGE_DIR, 'img_0.png'))\n",
    "\n",
    "USE_ID_FOR_IMAGES = test_by_id\n",
    "print(f\"\\u2705 Images by ID: {test_by_id}, by index: {test_by_idx}\")\n",
    "print(f\"\\u27a1\\ufe0f Using {'ID column' if USE_ID_FOR_IMAGES else 'row index'} for image lookup\")\n",
    "\n",
    "class PropertyDataset(Dataset):\n",
    "    \"\"\"Dataset for hybrid tabular + image model - FIXED for ID-based image lookup.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, X_tabular, y=None, config=CONFIG, train_mode=True, image_ids=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.X_tab = X_tabular.astype(np.float32)\n",
    "        self.y = y.astype(np.float32) if y is not None else None\n",
    "        self.config = config\n",
    "        # Store image IDs for correct lookup (img_{id}.png)\n",
    "        self.image_ids = image_ids if image_ids is not None else list(range(len(df)))\n",
    "        \n",
    "        if train_mode:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((config['image_size'], config['image_size'])),\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                T.RandomVerticalFlip(0.1),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize((config['image_size'], config['image_size'])),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        \n",
    "        self.blank = Image.new('RGB', (config['image_size'], config['image_size']), (128, 128, 128))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get image by ID (not row index!)\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(IMAGE_DIR, f'img_{int(img_id)}.png')\n",
    "        \n",
    "        img = self.blank\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "            except:\n",
    "\n",
    "                pass        return img_tensor, tab_tensor, torch.tensor(self.y[idx])\n",
    "\n",
    "                    return img_tensor, tab_tensor\n",
    "\n",
    "        img_tensor = self.transform(img)        if self.y is None:\n",
    "\n",
    "        tab_tensor = torch.from_numpy(self.X_tab[idx])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae339de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-Only Model (Image features only)\n",
    "class CNNOnlyModel(nn.Module):\n",
    "    \"\"\"CNN model using only satellite images.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        num_features = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, tab=None):\n",
    "        features = self.backbone(img)\n",
    "        return self.head(features).squeeze(1)\n",
    "\n",
    "\n",
    "# Hybrid Model (Tabular + Image fusion)\n",
    "class HybridModel(nn.Module):\n",
    "    \"\"\"Hybrid model combining tabular and image features.\"\"\"\n",
    "    \n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN branch\n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        cnn_features = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.cnn = backbone\n",
    "        \n",
    "        # Tabular branch\n",
    "        self.tabular = nn.Sequential(\n",
    "            nn.Linear(tabular_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Fusion head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(cnn_features + 64, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, tab):\n",
    "        img_feat = self.cnn(img)\n",
    "        tab_feat = self.tabular(tab)\n",
    "        combined = torch.cat([img_feat, tab_feat], dim=1)\n",
    "        return self.head(combined).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae959db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for img, tab, y in tqdm(loader, desc='Training', leave=False):\n",
    "        img, tab, y = img.to(device), tab.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img, tab)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(y)\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    for img, tab, y in loader:\n",
    "        img, tab = img.to(device), tab.to(device)\n",
    "        pred = model(img, tab)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        targets.extend(y.numpy())\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    return rmse, preds, targets\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for img, tab in loader:\n",
    "        img, tab = img.to(device), tab.to(device)\n",
    "        pred = model(img, tab)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "    \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a63cb",
   "metadata": {},
   "source": [
    "## 4. Train Hybrid Model (Tabular + Satellite Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "# Pass IMAGE IDs (from 'id' column) for correct image lookup (img_{id}.png)\n",
    "if USE_ID_FOR_IMAGES and 'id' in train_df.columns:\n",
    "    train_image_ids = train_data['id'].tolist()\n",
    "    val_image_ids = val_data['id'].tolist()\n",
    "    test_image_ids = test_df['id'].tolist() if 'id' in test_df.columns else list(range(len(test_df)))\n",
    "    print(\"Using 'id' column for image lookup\")\n",
    "else:\n",
    "    train_image_ids = train_data.index.tolist()\n",
    "    val_image_ids = val_data.index.tolist()\n",
    "    test_image_ids = list(range(len(test_df)))\n",
    "    print(\"Using row index for image lookup\")\n",
    "\n",
    "print(f\"Sample train image IDs: {train_image_ids[:5]}\")\n",
    "\n",
    "train_dataset = PropertyDataset(train_data, X_train, y_train, train_mode=True, image_ids=train_image_ids)\n",
    "val_dataset = PropertyDataset(val_data, X_val, y_val, train_mode=False, image_ids=val_image_ids)\n",
    "test_dataset = PropertyDataset(test_df, X_test, y=None, train_mode=False, original_indices=test_indices)\n",
    "\n",
    "print(f\"\\\\nImages loaded from: {IMAGE_DIR}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=0)print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)print(f\"Train batches: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f37161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hybrid model\n",
    "hybrid_model = HybridModel(tabular_dim=X_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(hybrid_model.parameters(), lr=CONFIG['lr'], weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in hybrid_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_rmse = float('inf')\n",
    "best_state = None\n",
    "history = {'train_loss': [], 'val_rmse': []}\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    train_loss = train_epoch(hybrid_model, train_loader, optimizer, criterion, DEVICE)\n",
    "    val_rmse, val_preds, val_targets = validate(hybrid_model, val_loader, DEVICE)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_rmse'].append(val_rmse)\n",
    "    \n",
    "    scheduler.step(val_rmse)\n",
    "    \n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_state = {k: v.cpu().clone() for k, v in hybrid_model.state_dict().items()}\n",
    "        marker = 'âœ“ (best)'\n",
    "    else:\n",
    "        marker = ''\n",
    "    \n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val RMSE: ${val_rmse:,.2f} {marker}\")\n",
    "\n",
    "print(f\"\\nðŸ† Best Validation RMSE: ${best_rmse:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba598a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Training Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "\n",
    "axes[1].plot(history['val_rmse'], marker='o', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Validation RMSE ($)')\n",
    "axes[1].set_title('Validation RMSE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "hybrid_model.load_state_dict(best_state)\n",
    "_, hybrid_val_preds, _ = validate(hybrid_model, val_loader, DEVICE)\n",
    "hybrid_results = evaluate_model(y_val, hybrid_val_preds, 'Hybrid Model (Tabular + Satellite)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6c4c0",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84190a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results_df = pd.DataFrame([xgb_results, hybrid_results])\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "display(results_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].bar(results_df['model'], results_df['RMSE'], color=['steelblue', 'coral'])\n",
    "axes[0].set_ylabel('RMSE ($)')\n",
    "axes[0].set_title('RMSE Comparison (Lower is Better)')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# RÂ² comparison\n",
    "axes[1].bar(results_df['model'], results_df['R2'], color=['steelblue', 'coral'])\n",
    "axes[1].set_ylabel('RÂ² Score')\n",
    "axes[1].set_title('RÂ² Comparison (Higher is Better)')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# MAPE comparison\n",
    "axes[2].bar(results_df['model'], results_df['MAPE'], color=['steelblue', 'coral'])\n",
    "axes[2].set_ylabel('MAPE (%)')\n",
    "axes[2].set_title('MAPE Comparison (Lower is Better)')\n",
    "axes[2].tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc16588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual scatter plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# XGBoost\n",
    "axes[0].scatter(y_val, xgb_val_pred, alpha=0.5, s=10)\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Price ($)')\n",
    "axes[0].set_ylabel('Predicted Price ($)')\n",
    "axes[0].set_title('XGBoost: Predicted vs Actual')\n",
    "\n",
    "# Hybrid\n",
    "axes[1].scatter(y_val, hybrid_val_preds, alpha=0.5, s=10, color='coral')\n",
    "axes[1].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Price ($)')\n",
    "axes[1].set_ylabel('Predicted Price ($)')\n",
    "axes[1].set_title('Hybrid Model: Predicted vs Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/predictions_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d6893",
   "metadata": {},
   "source": [
    "## 6. Grad-CAM Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ced18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"Grad-CAM implementation for CNN visualization.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(self._forward_hook)\n",
    "        target_layer.register_full_backward_hook(self._backward_hook)\n",
    "    \n",
    "    def _forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate(self, img_tensor, tab_tensor):\n",
    "        \"\"\"Generate Grad-CAM heatmap.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(img_tensor, tab_tensor)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        output.backward()\n",
    "        \n",
    "        # Compute weights\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        \n",
    "        # Compute CAM\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Normalize\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam\n",
    "\n",
    "\n",
    "def visualize_gradcam(model, img_path, tab_data, config, save_path=None):\n",
    "    \"\"\"Visualize Grad-CAM for a single property.\"\"\"\n",
    "    # Get target layer (last conv layer of ResNet)\n",
    "    target_layer = model.cnn.layer4[-1].conv2\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    original_img = np.array(img.resize((config['image_size'], config['image_size'])))\n",
    "    \n",
    "    transform = T.Compose([\n",
    "        T.Resize((config['image_size'], config['image_size'])),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
    "    img_tensor.requires_grad_(True)\n",
    "    \n",
    "    tab_tensor = torch.from_numpy(tab_data.astype(np.float32)).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    # Generate CAM\n",
    "    cam = gradcam.generate(img_tensor, tab_tensor)\n",
    "    \n",
    "    # Resize CAM to image size\n",
    "    cam_resized = cv2.resize(cam, (config['image_size'], config['image_size']))\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = np.uint8(0.4 * heatmap + 0.6 * original_img)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(original_img)\n",
    "    axes[0].set_title('Original Satellite Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cam_resized, cmap='jet')\n",
    "    axes[1].set_title('Grad-CAM Heatmap')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title('Grad-CAM Overlay\\n(Areas influencing price prediction)')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return cam_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Grad-CAM for sample properties\n",
    "sample_indices = val_data.sample(n=3, random_state=42).index.tolist()\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    row = train_df.loc[idx]\n",
    "    lat, lon = row[CONFIG['lat_col']], row[CONFIG['lon_col']]\n",
    "    img_path = fetcher._get_cache_path(lat, lon)\n",
    "    \n",
    "    if os.path.exists(img_path):\n",
    "        # Get tabular data for this sample\n",
    "        tab_idx = val_data.index.get_loc(idx) if idx in val_data.index else 0\n",
    "        tab_data = X_val[tab_idx] if tab_idx < len(X_val) else X_val[0]\n",
    "        \n",
    "        print(f\"\\nðŸ  Property {i+1}: Price = ${row['price']:,.0f}\")\n",
    "        visualize_gradcam(\n",
    "            hybrid_model, \n",
    "            img_path, \n",
    "            tab_data, \n",
    "            CONFIG,\n",
    "            save_path=f'../outputs/gradcam_sample_{i+1}.png'\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Image not found for sample {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480baec",
   "metadata": {},
   "source": [
    "## 7. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def24e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final predictions using the hybrid model\n",
    "hybrid_model.load_state_dict(best_state)\n",
    "test_predictions = predict(hybrid_model, test_loader, DEVICE)\n",
    "\n",
    "# Create submission dataframe with id and predicted_price\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'] if 'id' in test_df.columns else range(len(test_predictions)),\n",
    "    'predicted_price': test_predictions\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "submission_df.to_csv('../outputs/predictions.csv', index=False)\n",
    "print(f\"âœ… Predictions saved to ../outputs/predictions.csv\")\n",
    "print(f\"   Shape: {submission_df.shape}\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction statistics\n",
    "print(\"\\nðŸ“Š Prediction Statistics:\")\n",
    "print(f\"   Mean:   ${test_predictions.mean():,.2f}\")\n",
    "print(f\"   Median: ${np.median(test_predictions):,.2f}\")\n",
    "print(f\"   Min:    ${test_predictions.min():,.2f}\")\n",
    "print(f\"   Max:    ${test_predictions.max():,.2f}\")\n",
    "print(f\"   Std:    ${test_predictions.std():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d25c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': best_state,\n",
    "    'config': CONFIG,\n",
    "    'feature_cols': feature_cols,\n",
    "    'results': results_df.to_dict()\n",
    "}, '../outputs/hybrid_model.pth')\n",
    "\n",
    "print(\"âœ… Model saved to ../outputs/hybrid_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f580b6",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“ Summary\n",
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "| Model | RMSE | MAE | RÂ² | MAPE |\n",
    "|-------|------|-----|-------|------|\n",
    "| XGBoost (Tabular Only) | $ | $ | | % |\n",
    "| Hybrid (Tabular + Satellite) | $ | $ | | % |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Visual Features Impact**: [Document impact of satellite images]\n",
    "2. **Grad-CAM Insights**: [What areas influence predictions - green cover, roads, etc.]\n",
    "3. **Improvement from Baseline**: [% improvement from tabular-only to hybrid]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
